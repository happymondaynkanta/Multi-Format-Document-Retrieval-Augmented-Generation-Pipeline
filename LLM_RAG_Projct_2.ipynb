{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1J2gec3AV8G4_0eLLDEdOpDH7nWRW_4S2",
      "authorship_tag": "ABX9TyPFdBHM1BhOxEs1r78w9NSM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happymondaynkanta/Multi-Format-Document-Retrieval-Augmented-Generation-Pipeline/blob/main/LLM_RAG_Projct_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Install required libraries: LangChain, ChromaDB, HuggingFace, PDF/DOCX/PPTX loaders\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jKdGr9AUwQUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPibjVwfcFk7"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U \\\n",
        "  langchain-community \\\n",
        "  langchain-text-splitters \\\n",
        "  langchain-chroma \\\n",
        "  sentence-transformers \\\n",
        "  chromadb \\\n",
        "  pypdf \\\n",
        "  docx2txt \\\n",
        "  python-pptx \\\n",
        "  beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Mount Google Drive in Colab and define base directory for documents ---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eGOH0wj-wcyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ðŸ‘‡ change only if your Drive path differs\n",
        "DATA_DIR = \"/content/drive/MyDrive/project_two\"\n"
      ],
      "metadata": {
        "id": "Eca7SGe7esE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import standard libraries and format-specific loaders (PDF, DOCX, PPTX)\n"
      ],
      "metadata": {
        "id": "I3PL8NWtw-IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "import re\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
        "from pptx import Presentation  # python-pptx"
      ],
      "metadata": {
        "id": "YX3c2-wIxF-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split loaded documents into manageable chunks with overlap for embeddings ---\n"
      ],
      "metadata": {
        "id": "SaTT-SlZxNw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_pdf(path: Path) -> List[Document]:\n",
        "    # PyPDFLoader returns one Document per page (nice metadata: \"page\")\n",
        "    loader = PyPDFLoader(str(path))\n",
        "    docs = loader.load()\n",
        "    for d in docs:\n",
        "        d.metadata.update({\n",
        "            \"source\": str(path),\n",
        "            \"filename\": path.name,\n",
        "            \"ext\": path.suffix.lower(),\n",
        "            \"week\": path.parent.name  # e.g., \"Week 1\"\n",
        "        })\n",
        "    return docs\n",
        "\n",
        "def load_docx(path: Path) -> List[Document]:\n",
        "    loader = Docx2txtLoader(str(path))\n",
        "    docs = loader.load()\n",
        "    # Docx2txtLoader returns a single Document\n",
        "    for d in docs:\n",
        "        d.metadata.update({\n",
        "            \"source\": str(path),\n",
        "            \"filename\": path.name,\n",
        "            \"ext\": path.suffix.lower(),\n",
        "            \"week\": path.parent.name\n",
        "        })\n",
        "    return docs\n",
        "\n",
        "def load_pptx(path: Path) -> List[Document]:\n",
        "    prs = Presentation(str(path))\n",
        "    docs = []\n",
        "    for i, slide in enumerate(prs.slides, start=1):\n",
        "        # collect all text on the slide\n",
        "        chunks = []\n",
        "        for shape in slide.shapes:\n",
        "            if hasattr(shape, \"has_text_frame\") and shape.has_text_frame:\n",
        "                txt = \"\\n\".join(p.text for p in shape.text_frame.paragraphs if p.text)\n",
        "                if txt.strip():\n",
        "                    chunks.append(txt.strip())\n",
        "        slide_text = \"\\n\".join(chunks).strip()\n",
        "        if slide_text:\n",
        "            docs.append(\n",
        "                Document(\n",
        "                    page_content=slide_text,\n",
        "                    metadata={\n",
        "                        \"source\": str(path),\n",
        "                        \"filename\": path.name,\n",
        "                        \"ext\": path.suffix.lower(),\n",
        "                        \"slide\": i,\n",
        "                        \"week\": path.parent.name\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "    return docs\n",
        "\n",
        "def load_all(base_dir: str) -> List[Document]:\n",
        "    base = Path(base_dir)\n",
        "    all_docs: List[Document] = []\n",
        "    for p in base.rglob(\"*\"):\n",
        "        if not p.is_file():\n",
        "            continue\n",
        "        ext = p.suffix.lower()\n",
        "        try:\n",
        "            if ext == \".pdf\":\n",
        "                all_docs += load_pdf(p)\n",
        "            elif ext == \".docx\":\n",
        "                all_docs += load_docx(p)\n",
        "            elif ext == \".pptx\":\n",
        "                all_docs += load_pptx(p)\n",
        "            # ignore other file types\n",
        "        except Exception as e:\n",
        "            print(f\"[skip] {p.name}: {e}\")\n",
        "    return all_docs\n",
        "\n",
        "docs = load_all(DATA_DIR)\n",
        "\n",
        "# optional: filter empty/tiny pages\n",
        "docs = [d for d in docs if len(d.page_content.split()) > 10]\n",
        "\n",
        "print(f\"Loaded {len(docs)} Documents\")\n",
        "# quick peek\n",
        "for d in docs[:5]:\n",
        "    print(d.metadata, \"â†’\", d.page_content[:120].replace(\"\\n\",\" \"), \"â€¦\")\n"
      ],
      "metadata": {
        "id": "MRvEwajefBup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Documents into Chunks\n",
        "## Encode chunks into semantic embeddings and store them in ChromaDB ---\n"
      ],
      "metadata": {
        "id": "w8fd9A5qxhP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Chunks: {len(chunks)}\")\n",
        "\n",
        "# local, free embeddings (fast on Pro GPU)\n",
        "import torch\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "emb = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={\"device\": device}\n",
        ")\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=emb,\n",
        "    collection_name=\"project_two\",\n",
        "    persist_directory=\"chroma_db\"\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"Chroma index ready.\")\n"
      ],
      "metadata": {
        "id": "4Z8vSWUVfD2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## --- Define function to retrieve context and generate grounded answers with LLM ---\n"
      ],
      "metadata": {
        "id": "GVR3CdkAx1Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import ai\n",
        "\n",
        "def ask(question, k=5, max_chars=1200):\n",
        "    ctx_docs = retriever.get_relevant_documents(question)\n",
        "    context = \"\\n\\n\".join(\n",
        "        f\"[{i+1}] {d.metadata.get('filename')} ({d.metadata.get('week')})\\n{d.page_content[:max_chars]}\"\n",
        "        for i, d in enumerate(ctx_docs)\n",
        "    )\n",
        "    prompt = (\n",
        "        \"You are a helpful assistant. Answer ONLY from the context.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
        "    )\n",
        "    return ai.generate_text(prompt), ctx_docs\n",
        "\n",
        "answer, sources = ask(\"Then who is Happy?\")\n",
        "print(answer)\n",
        "print(\"\\nSources:\")\n",
        "for s in sources:\n",
        "    print(\"-\", s.metadata.get(\"filename\"), \"|\", s.metadata.get(\"week\"))\n"
      ],
      "metadata": {
        "id": "STLyyf9KfI7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}